{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('census.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  final-weight   education  education-num  \\\n",
       "0   39          State-gov         77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors             13   \n",
       "2   38            Private        215646     HS-grad              9   \n",
       "\n",
       "        marital-status          occupation    relationship    race    sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White   Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White   Male   \n",
       "\n",
       "   capital-gain  capital-loos  hour-per-week  native-country  income  \n",
       "0          2174             0             40   United-States   <=50K  \n",
       "1             0             0             13   United-States   <=50K  \n",
       "2             0             0             40   United-States   <=50K  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 14 colunas presentes no dataset fornecido, sendo 13 delas variáveis características (dados de entrada) e um delas uma variável-alvo (que queremos que o nosso modelo seja capaz de prever).\n",
    "\n",
    "As variáveis características são:\n",
    "\n",
    "    age             - A idade do usuário\n",
    "    Workclass       - Profissão do usuário\n",
    "    final-weight    - Renda final do usuário\n",
    "    education       - Educação do usuário\n",
    "    education-num   - ID da educação do usuário\n",
    "    marital-status  - Estado-civil do usuário\n",
    "    occupation      - Ocupação do usuário\n",
    "    relationship    - Relacionamento do usuário\n",
    "    race            - Raça do usuário\n",
    "    sex             - Sexo do usuário\n",
    "    capital-gain    - Capital ganho\n",
    "    capital-loss    - Capital perdido\n",
    "    hour-per-week   - Horas por semana\n",
    "    native-country  - Cidade natal\n",
    "\n",
    "A variável-alvo é:\n",
    "\n",
    "    income    - um tipo *binário* que indica a renda do usuário: \n",
    "            <=50k      - Usuário com renda menor ou igual a 50000\n",
    "             >50k      - Usuário com renda maior a 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "final-weight      32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education-num     32561 non-null int64\n",
      "marital-status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital-gain      32561 non-null int64\n",
      "capital-loos      32561 non-null int64\n",
      "hour-per-week     32561 non-null int64\n",
      "native-country    32561 non-null object\n",
      "income            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É notado que existem variáveis do tipo ``float64`` (números \"decimais\"), variáveis do tipo ``int64`` (números inteiros) e do tipo ``object`` (nesse caso são *strings*, ou texto). \n",
    "\n",
    "Como a maioria dos algoritmos de aprendizado estatístico supervisionado só aceita valores numéricos como entrada, é necessário então o pré-processamento das variáveis do tipo \"object\" antes de usar esse dataset como entrada para o treinamento de um modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ``describe()`` gera várias informações sobre as variáveis numéricas que também podem ser úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  final-weight  education-num  capital-gain  capital-loos  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hour-per-week  \n",
       "count   32561.000000  \n",
       "mean       40.437456  \n",
       "std        12.347429  \n",
       "min         1.000000  \n",
       "25%        40.000000  \n",
       "50%        40.000000  \n",
       "75%        45.000000  \n",
       "max        99.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição das features do nosso modelo\n",
    "Para isso, criaremos a váriavel X que receberá as variáveis características do nosso modelo, e a variavel y que receberá a variável-alvo do nosso modelo.\n",
    "\n",
    "Também retiraremos as colunas 'clientid' que não terá relevância no nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'final-weight', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loos', 'hour-per-week', 'native-country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando as colunas do nosso dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das colunas que serão features (nota-se que a coluna 'clientid' não está presente)\n",
    "features = [\n",
    "    'age', 'workclass', 'final-weight', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loos', 'hour-per-week', 'native-country'\n",
    "]\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"income\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df[features].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de variáveis categóricas\n",
    "\n",
    "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
    "\n",
    "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbp = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte da transformação de categóricos para inteiros\n",
    "\n",
    "X[:, 1] = lbp.fit_transform(X[:, 1])\n",
    "\n",
    "X[:, 3] = lbp.fit_transform(X[:, 3])\n",
    "\n",
    "X[:, 5] = lbp.fit_transform(X[:, 5])\n",
    "\n",
    "X[:, 6] = lbp.fit_transform(X[:, 6])\n",
    "\n",
    "X[:, 7] = lbp.fit_transform(X[:, 7])\n",
    "X\n",
    "X[:, 8] = lbp.fit_transform(X[:, 8])\n",
    "\n",
    "X[:, 9] = lbp.fit_transform(X[:, 9])\n",
    "\n",
    "X[:, 13] = lbp.fit_transform(X[:, 13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checando se os dados foram alterados das três primeiras linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  final-weight   education  education-num  \\\n",
       "0   39          State-gov         77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors             13   \n",
       "2   38            Private        215646     HS-grad              9   \n",
       "\n",
       "        marital-status          occupation    relationship    race    sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White   Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White   Male   \n",
       "\n",
       "   capital-gain  capital-loos  hour-per-week  native-country  income  \n",
       "0          2174             0             40   United-States   <=50K  \n",
       "1             0             0             13   United-States   <=50K  \n",
       "2             0             0             40   United-States   <=50K  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 7, 77516, 9, 13, 4, 1, 1, 4, 1, 2174, 0, 40, 39],\n",
       "       [50, 6, 83311, 9, 13, 2, 4, 0, 4, 1, 0, 0, 13, 39],\n",
       "       [38, 4, 215646, 11, 9, 0, 6, 1, 4, 1, 0, 0, 40, 39]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados alterados :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observação:\n",
    "Não fizemos isso certo totalmente, pois colocamos todas as variavéis do tipo catégorico como ordinal, como por exemplo:\n",
    "O sexo Masculino está com o valor 0, e o sexo Feminino está com o valor 1, assim, o sexo Feminino teria maior influência do que o sexo masculino.\n",
    "##### por isso devemos usar as variaveis do tipo 'dummy' que não tem relevância no treinamento dos modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Transformação do tipo 'race' para tipo dummy, que seria sem importância\n",
    "ohe_x = OneHotEncoder(categorical_features=[1, 3, 5, 6, 7, 8, 9, 13])\n",
    "\n",
    "X = ohe_x.fit_transform(X).toarray()\n",
    "\n",
    "# transformando a classe\n",
    "ohe_y = LabelEncoder()\n",
    "\n",
    "y = ohe_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalonamento dos dados númericos\n",
    "Como podemos ver nos dados há uma grande diferença de números altos e números baixos, por isso devemos fazer o escalonamento dos dados para deixa-los na mesma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2444502 , -0.17429511, -0.26209736, ...,  0.1484529 ,\n",
       "        -0.21665953, -0.03542945],\n",
       "       [-0.2444502 , -0.17429511, -0.26209736, ..., -0.14592048,\n",
       "        -0.21665953, -2.22215312],\n",
       "       [-0.2444502 , -0.17429511, -0.26209736, ..., -0.14592048,\n",
       "        -0.21665953, -0.03542945],\n",
       "       ...,\n",
       "       [-0.2444502 , -0.17429511, -0.26209736, ..., -0.14592048,\n",
       "        -0.21665953, -0.03542945],\n",
       "       [-0.2444502 , -0.17429511, -0.26209736, ..., -0.14592048,\n",
       "        -0.21665953, -1.65522476],\n",
       "       [-0.2444502 , -0.17429511, -0.26209736, ...,  1.88842434,\n",
       "        -0.21665953, -0.03542945]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando os modelos de classificação\n",
    "Finalizado o pré-processamento, já temos o conjunto de dados no formato necessário para o treinamento do nosso modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações dos algoritmos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Redes neurais com keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando o dataset em um conjunto de treino e um conjunto de teste\n",
    "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes \n",
    "O algoritmo Naive Bayes é um algoritmo simples de classificação, que utiliza dados históricos para prever a classificação de um novo dado. Ele funciona calculando a probabilidade de um evento ocorrer dado que outro evento já ocorreu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte do treinamento\n",
    "nb.fit(X_train, y_train)\n",
    "# Parte do teste, predict serve para testar\n",
    "y_pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 48.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Naive Bayes\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_nb), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.32      0.48      6159\n",
      "           1       0.32      0.97      0.48      1982\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      8141\n",
      "   macro avg       0.64      0.65      0.48      8141\n",
      "weighted avg       0.81      0.48      0.48      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1978, 4181],\n",
       "       [  55, 1927]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo Naive Bayes\n",
    "Tive que fazer vários testes cada um com a transformação diferente, e cheguei a estes resultados:\n",
    "\n",
    "    47,67% Naive Bayes (labelencoder + onehotencoder + escalonamento)\n",
    "    79,52% Naive Bayes (labelencoder)\n",
    "    79,50% Naive Bayes (labelencoder + onehotencoder)\n",
    "    80,57% Naive Bayes (labelencoder + escalonamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "O algoritmo Decision Tree são modelos estatísticos que utilizam um treinamento supervisionado para a classificação e previsão de dados, Estes modelos utilizam a estratégia de dividir para conquistar: um problema complexo é decomposto em sub-problemas mais simples e recursivamente esta técnica é aplicada a cada sub-problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_dt), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      6159\n",
      "           1       0.62      0.63      0.62      1982\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      8141\n",
      "   macro avg       0.75      0.75      0.75      8141\n",
      "weighted avg       0.82      0.82      0.82      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5407,  752],\n",
       "       [ 742, 1240]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo Decision Tree\n",
    "Fiz vários testes porém com o algoritmo Decision Tree não houve tanta diferença nos resultados, como podemos observar abaixo:\n",
    "\n",
    "    81,02% Árvore de decisão (labelencoder + onehotencoder + escalonamento)\n",
    "    81,28% Árvore de decisão (labelencoder)\n",
    "    81,02% Árvore de decisão (labelencoder + onehotencoder)\n",
    "    81,28% Árvore de decisão (labelencoder + escalonamento) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "O algoritmo Random Forest cria uma floresta de um modo aleatório, criando várias árvores de decisão e as combinando,cada árvore tenta estimar uma classificação e isso é chamado como “voto”, assim, para obter uma predição com maior acurácia e mais estável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=40, criterion= 'entropy', random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 85.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rf), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      6159\n",
      "           1       0.73      0.61      0.66      1982\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8141\n",
      "   macro avg       0.80      0.77      0.78      8141\n",
      "weighted avg       0.84      0.85      0.84      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5714,  445],\n",
       "       [ 782, 1200]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo Random Forest\n",
    "No algoritmo Random Forest como já era esperado, não houve tanta diferença, e cheguei a estes resultados:\n",
    "    \n",
    "    84.76% Random Forest (labelencoder + onehotencoder + escalonamento)\n",
    "    84.81% Random Forest (labelencoder)\n",
    "    84.89% Random Forest (labelencoder + onehotencoder)\n",
    "    84.79% Random Forest (labelencoder + escalonamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN (Vizinhos mais próximos)\n",
    "O algoritmo KNN ou k-vizinhos mais próximos é um algoritmo bem simples de machine learning. Ele usa algum tipo de medida de similaridade para dizer em qual classe o novo dado se classifica, neste caso utilizaremos 5 vizinhos mais próximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski', p = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_knn), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      6159\n",
      "           1       0.65      0.57      0.61      1982\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      8141\n",
      "   macro avg       0.76      0.74      0.75      8141\n",
      "weighted avg       0.81      0.82      0.82      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5407,  752],\n",
       "       [ 742, 1240]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo kNN\n",
    "Aqui podemos observar que houve diferença dos resultados, com os testes feitos cheguei a estes resultados:\n",
    "    \n",
    "    82.23% kNN  (labelencoder + onehotencoder + escalonamento)\n",
    "    77.46% kNN (labelencoder)\n",
    "    77.60% kNN  (labelencoder + onehotencoder)\n",
    "    82.19% kNN (labelencoder + escalonamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logistica\n",
    "O algoritmo de regressão logística é usada onde uma saída discreta é esperada, (ex. Prever se um usuário é um bom ou mal pagador).Normalmente, a regressão logística usa alguma função para espremer valores para um determinado intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rl = rl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 85.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rl), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      6159\n",
      "           1       0.74      0.61      0.67      1982\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8141\n",
      "   macro avg       0.81      0.77      0.79      8141\n",
      "weighted avg       0.85      0.85      0.85      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5741,  418],\n",
       "       [ 767, 1215]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo Regressão Logística\n",
    "Na regressão Logística houve diferença apenas utilizando todos os pré-processamentos, assim cheguei a estes resultados:\n",
    "\n",
    "    84.95% Regressão Log  (labelencoder + onehotencoder + escalonamento)\n",
    "    79.09% Regressão Log (labelencoder)\n",
    "    79.54% Regressão Log (labelencoder + onehotencoder)\n",
    "    81.84% Regressão Log (labelencoder + escalonamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Máquinas de vetores de suporte)\n",
    "O algoritmo de SVM separa os pontos de dados usando uma linha. Esta linha é escolhida de tal forma que será mais importante dos pontos de dados mais próximos em 2 categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 85.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo SVM\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_svm), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.90      6159\n",
      "           1       0.75      0.58      0.66      1982\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8141\n",
      "   macro avg       0.81      0.76      0.78      8141\n",
      "weighted avg       0.84      0.85      0.84      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5767,  392],\n",
       "       [ 823, 1159]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo SVM\n",
    "Tive que fazer vários testes cada um com a transformação diferente, e cheguei a estes resultados:\n",
    "\n",
    "     0.8507% SVM(labelencoder + onehotencoder + escalonamento)\n",
    "     ? SVM (labelencoder) - Muito lento\n",
    "     ? SVM (labelencoder + onehotencoder) - Muito lento\n",
    "     0.8507% SVM (labelencoder + escalonamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neurais\n",
    "O objetivo do algoritmo de Redes neurais é imitar o sistema nervoso de humanos no processo de aprendizagem, ela é inspirada nas redes neurais biológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais com a biblioteca ``sklearn``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_sk = MLPClassifier(verbose = True, max_iter= 1000, tol = 0.000010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37773631\n",
      "Iteration 2, loss = 0.32775564\n",
      "Iteration 3, loss = 0.31885236\n",
      "Iteration 4, loss = 0.31164835\n",
      "Iteration 5, loss = 0.30672537\n",
      "Iteration 6, loss = 0.30252327\n",
      "Iteration 7, loss = 0.29880388\n",
      "Iteration 8, loss = 0.29695049\n",
      "Iteration 9, loss = 0.29397236\n",
      "Iteration 10, loss = 0.29175833\n",
      "Iteration 11, loss = 0.28963984\n",
      "Iteration 12, loss = 0.28803503\n",
      "Iteration 13, loss = 0.28665784\n",
      "Iteration 14, loss = 0.28498709\n",
      "Iteration 15, loss = 0.28250970\n",
      "Iteration 16, loss = 0.28204775\n",
      "Iteration 17, loss = 0.28012706\n",
      "Iteration 18, loss = 0.27855067\n",
      "Iteration 19, loss = 0.27792460\n",
      "Iteration 20, loss = 0.27614555\n",
      "Iteration 21, loss = 0.27541728\n",
      "Iteration 22, loss = 0.27386782\n",
      "Iteration 23, loss = 0.27349508\n",
      "Iteration 24, loss = 0.27172983\n",
      "Iteration 25, loss = 0.27084700\n",
      "Iteration 26, loss = 0.27072783\n",
      "Iteration 27, loss = 0.26905047\n",
      "Iteration 28, loss = 0.26843675\n",
      "Iteration 29, loss = 0.26734871\n",
      "Iteration 30, loss = 0.26687094\n",
      "Iteration 31, loss = 0.26584830\n",
      "Iteration 32, loss = 0.26526571\n",
      "Iteration 33, loss = 0.26413682\n",
      "Iteration 34, loss = 0.26347522\n",
      "Iteration 35, loss = 0.26263288\n",
      "Iteration 36, loss = 0.26151598\n",
      "Iteration 37, loss = 0.26074032\n",
      "Iteration 38, loss = 0.25953619\n",
      "Iteration 39, loss = 0.25922329\n",
      "Iteration 40, loss = 0.25791711\n",
      "Iteration 41, loss = 0.25815445\n",
      "Iteration 42, loss = 0.25679037\n",
      "Iteration 43, loss = 0.25660729\n",
      "Iteration 44, loss = 0.25617972\n",
      "Iteration 45, loss = 0.25521919\n",
      "Iteration 46, loss = 0.25375097\n",
      "Iteration 47, loss = 0.25425324\n",
      "Iteration 48, loss = 0.25284462\n",
      "Iteration 49, loss = 0.25193067\n",
      "Iteration 50, loss = 0.25155147\n",
      "Iteration 51, loss = 0.25126233\n",
      "Iteration 52, loss = 0.25017437\n",
      "Iteration 53, loss = 0.24944482\n",
      "Iteration 54, loss = 0.24962842\n",
      "Iteration 55, loss = 0.24894819\n",
      "Iteration 56, loss = 0.24881301\n",
      "Iteration 57, loss = 0.24897092\n",
      "Iteration 58, loss = 0.24647128\n",
      "Iteration 59, loss = 0.24604732\n",
      "Iteration 60, loss = 0.24637194\n",
      "Iteration 61, loss = 0.24560169\n",
      "Iteration 62, loss = 0.24432317\n",
      "Iteration 63, loss = 0.24688227\n",
      "Iteration 64, loss = 0.24472213\n",
      "Iteration 65, loss = 0.24323089\n",
      "Iteration 66, loss = 0.24207994\n",
      "Iteration 67, loss = 0.24291079\n",
      "Iteration 68, loss = 0.24252381\n",
      "Iteration 69, loss = 0.24141527\n",
      "Iteration 70, loss = 0.24053859\n",
      "Iteration 71, loss = 0.24140321\n",
      "Iteration 72, loss = 0.23996511\n",
      "Iteration 73, loss = 0.24030892\n",
      "Iteration 74, loss = 0.23977037\n",
      "Iteration 75, loss = 0.23887223\n",
      "Iteration 76, loss = 0.23801139\n",
      "Iteration 77, loss = 0.23846119\n",
      "Iteration 78, loss = 0.23776604\n",
      "Iteration 79, loss = 0.23810224\n",
      "Iteration 80, loss = 0.23740167\n",
      "Iteration 81, loss = 0.23694145\n",
      "Iteration 82, loss = 0.23531477\n",
      "Iteration 83, loss = 0.23544251\n",
      "Iteration 84, loss = 0.23469878\n",
      "Iteration 85, loss = 0.23401250\n",
      "Iteration 86, loss = 0.23349758\n",
      "Iteration 87, loss = 0.23376848\n",
      "Iteration 88, loss = 0.23337528\n",
      "Iteration 89, loss = 0.23293435\n",
      "Iteration 90, loss = 0.23441155\n",
      "Iteration 91, loss = 0.23197746\n",
      "Iteration 92, loss = 0.23145495\n",
      "Iteration 93, loss = 0.23160916\n",
      "Iteration 94, loss = 0.23201802\n",
      "Iteration 95, loss = 0.23023584\n",
      "Iteration 96, loss = 0.23119973\n",
      "Iteration 97, loss = 0.23049189\n",
      "Iteration 98, loss = 0.22941568\n",
      "Iteration 99, loss = 0.22965756\n",
      "Iteration 100, loss = 0.22901316\n",
      "Iteration 101, loss = 0.22791576\n",
      "Iteration 102, loss = 0.22895738\n",
      "Iteration 103, loss = 0.22819094\n",
      "Iteration 104, loss = 0.22775086\n",
      "Iteration 105, loss = 0.22694228\n",
      "Iteration 106, loss = 0.22757655\n",
      "Iteration 107, loss = 0.22624920\n",
      "Iteration 108, loss = 0.22508309\n",
      "Iteration 109, loss = 0.22738866\n",
      "Iteration 110, loss = 0.22667416\n",
      "Iteration 111, loss = 0.22544685\n",
      "Iteration 112, loss = 0.22603490\n",
      "Iteration 113, loss = 0.22472770\n",
      "Iteration 114, loss = 0.22517823\n",
      "Iteration 115, loss = 0.22431662\n",
      "Iteration 116, loss = 0.22395258\n",
      "Iteration 117, loss = 0.22339470\n",
      "Iteration 118, loss = 0.22269394\n",
      "Iteration 119, loss = 0.22318002\n",
      "Iteration 120, loss = 0.22449202\n",
      "Iteration 121, loss = 0.22360607\n",
      "Iteration 122, loss = 0.22203977\n",
      "Iteration 123, loss = 0.22235617\n",
      "Iteration 124, loss = 0.22199358\n",
      "Iteration 125, loss = 0.22087451\n",
      "Iteration 126, loss = 0.22105263\n",
      "Iteration 127, loss = 0.22071836\n",
      "Iteration 128, loss = 0.22078658\n",
      "Iteration 129, loss = 0.21939992\n",
      "Iteration 130, loss = 0.22039323\n",
      "Iteration 131, loss = 0.21940849\n",
      "Iteration 132, loss = 0.21977920\n",
      "Iteration 133, loss = 0.21901333\n",
      "Iteration 134, loss = 0.21806593\n",
      "Iteration 135, loss = 0.21773096\n",
      "Iteration 136, loss = 0.21844426\n",
      "Iteration 137, loss = 0.21762876\n",
      "Iteration 138, loss = 0.21857238\n",
      "Iteration 139, loss = 0.21778369\n",
      "Iteration 140, loss = 0.21797827\n",
      "Iteration 141, loss = 0.21588455\n",
      "Iteration 142, loss = 0.21603634\n",
      "Iteration 143, loss = 0.21598752\n",
      "Iteration 144, loss = 0.21610025\n",
      "Iteration 145, loss = 0.21542445\n",
      "Iteration 146, loss = 0.21511134\n",
      "Iteration 147, loss = 0.21605566\n",
      "Iteration 148, loss = 0.21473306\n",
      "Iteration 149, loss = 0.21601429\n",
      "Iteration 150, loss = 0.21362779\n",
      "Iteration 151, loss = 0.21363622\n",
      "Iteration 152, loss = 0.21364747\n",
      "Iteration 153, loss = 0.21423004\n",
      "Iteration 154, loss = 0.21282791\n",
      "Iteration 155, loss = 0.21393923\n",
      "Iteration 156, loss = 0.21524705\n",
      "Iteration 157, loss = 0.21250167\n",
      "Iteration 158, loss = 0.21248611\n",
      "Iteration 159, loss = 0.21203849\n",
      "Iteration 160, loss = 0.21151349\n",
      "Iteration 161, loss = 0.21218200\n",
      "Iteration 162, loss = 0.21201347\n",
      "Iteration 163, loss = 0.21252594\n",
      "Iteration 164, loss = 0.21048017\n",
      "Iteration 165, loss = 0.21027722\n",
      "Iteration 166, loss = 0.21029262\n",
      "Iteration 167, loss = 0.20953597\n",
      "Iteration 168, loss = 0.21109854\n",
      "Iteration 169, loss = 0.20976487\n",
      "Iteration 170, loss = 0.20929424\n",
      "Iteration 171, loss = 0.21035774\n",
      "Iteration 172, loss = 0.21010856\n",
      "Iteration 173, loss = 0.20987270\n",
      "Iteration 174, loss = 0.20909168\n",
      "Iteration 175, loss = 0.20769426\n",
      "Iteration 176, loss = 0.20638903\n",
      "Iteration 177, loss = 0.20728893\n",
      "Iteration 178, loss = 0.20792828\n",
      "Iteration 179, loss = 0.20772518\n",
      "Iteration 180, loss = 0.20666914\n",
      "Iteration 181, loss = 0.20856537\n",
      "Iteration 182, loss = 0.20640215\n",
      "Iteration 183, loss = 0.20671247\n",
      "Iteration 184, loss = 0.20733701\n",
      "Iteration 185, loss = 0.20586361\n",
      "Iteration 186, loss = 0.20633988\n",
      "Iteration 187, loss = 0.20546792\n",
      "Iteration 188, loss = 0.20603610\n",
      "Iteration 189, loss = 0.20424468\n",
      "Iteration 190, loss = 0.20442030\n",
      "Iteration 191, loss = 0.20569376\n",
      "Iteration 192, loss = 0.20442053\n",
      "Iteration 193, loss = 0.20381279\n",
      "Iteration 194, loss = 0.20604084\n",
      "Iteration 195, loss = 0.20423541\n",
      "Iteration 196, loss = 0.20619899\n",
      "Iteration 197, loss = 0.20299100\n",
      "Iteration 198, loss = 0.20327333\n",
      "Iteration 199, loss = 0.20431163\n",
      "Iteration 200, loss = 0.20227460\n",
      "Iteration 201, loss = 0.20377123\n",
      "Iteration 202, loss = 0.20181986\n",
      "Iteration 203, loss = 0.20260678\n",
      "Iteration 204, loss = 0.20107725\n",
      "Iteration 205, loss = 0.20108625\n",
      "Iteration 206, loss = 0.20090224\n",
      "Iteration 207, loss = 0.20215635\n",
      "Iteration 208, loss = 0.20139146\n",
      "Iteration 209, loss = 0.20082051\n",
      "Iteration 210, loss = 0.20120953\n",
      "Iteration 211, loss = 0.20020927\n",
      "Iteration 212, loss = 0.20271775\n",
      "Iteration 213, loss = 0.20089409\n",
      "Iteration 214, loss = 0.20031599\n",
      "Iteration 215, loss = 0.20094506\n",
      "Iteration 216, loss = 0.20149637\n",
      "Iteration 217, loss = 0.20010784\n",
      "Iteration 218, loss = 0.19927005\n",
      "Iteration 219, loss = 0.19949950\n",
      "Iteration 220, loss = 0.19879627\n",
      "Iteration 221, loss = 0.19975803\n",
      "Iteration 222, loss = 0.19802340\n",
      "Iteration 223, loss = 0.19899153\n",
      "Iteration 224, loss = 0.19861959\n",
      "Iteration 225, loss = 0.19817143\n",
      "Iteration 226, loss = 0.19751452\n",
      "Iteration 227, loss = 0.19836730\n",
      "Iteration 228, loss = 0.19849747\n",
      "Iteration 229, loss = 0.19749725\n",
      "Iteration 230, loss = 0.19760556\n",
      "Iteration 231, loss = 0.19657143\n",
      "Iteration 232, loss = 0.19789506\n",
      "Iteration 233, loss = 0.19681807\n",
      "Iteration 234, loss = 0.19725542\n",
      "Iteration 235, loss = 0.19597450\n",
      "Iteration 236, loss = 0.19650920\n",
      "Iteration 237, loss = 0.19625865\n",
      "Iteration 238, loss = 0.19777422\n",
      "Iteration 239, loss = 0.19488206\n",
      "Iteration 240, loss = 0.19676369\n",
      "Iteration 241, loss = 0.19609472\n",
      "Iteration 242, loss = 0.19596339\n",
      "Iteration 243, loss = 0.19533896\n",
      "Iteration 244, loss = 0.19377658\n",
      "Iteration 245, loss = 0.19447462\n",
      "Iteration 246, loss = 0.19426167\n",
      "Iteration 247, loss = 0.19465522\n",
      "Iteration 248, loss = 0.19569974\n",
      "Iteration 249, loss = 0.19634381\n",
      "Iteration 250, loss = 0.19387116\n",
      "Iteration 251, loss = 0.19324353\n",
      "Iteration 252, loss = 0.19427042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.19418277\n",
      "Iteration 254, loss = 0.19253436\n",
      "Iteration 255, loss = 0.19354540\n",
      "Iteration 256, loss = 0.19368541\n",
      "Iteration 257, loss = 0.19301223\n",
      "Iteration 258, loss = 0.19206748\n",
      "Iteration 259, loss = 0.19296638\n",
      "Iteration 260, loss = 0.19099608\n",
      "Iteration 261, loss = 0.19254234\n",
      "Iteration 262, loss = 0.19211566\n",
      "Iteration 263, loss = 0.19122621\n",
      "Iteration 264, loss = 0.19221314\n",
      "Iteration 265, loss = 0.19150479\n",
      "Iteration 266, loss = 0.19163912\n",
      "Iteration 267, loss = 0.19232325\n",
      "Iteration 268, loss = 0.19200426\n",
      "Iteration 269, loss = 0.19073671\n",
      "Iteration 270, loss = 0.19098809\n",
      "Iteration 271, loss = 0.19226113\n",
      "Iteration 272, loss = 0.19097243\n",
      "Iteration 273, loss = 0.19112130\n",
      "Iteration 274, loss = 0.19183469\n",
      "Iteration 275, loss = 0.18997281\n",
      "Iteration 276, loss = 0.19198454\n",
      "Iteration 277, loss = 0.18992767\n",
      "Iteration 278, loss = 0.19150587\n",
      "Iteration 279, loss = 0.18904338\n",
      "Iteration 280, loss = 0.18991324\n",
      "Iteration 281, loss = 0.19049473\n",
      "Iteration 282, loss = 0.18834128\n",
      "Iteration 283, loss = 0.19074436\n",
      "Iteration 284, loss = 0.18824910\n",
      "Iteration 285, loss = 0.18858876\n",
      "Iteration 286, loss = 0.18959363\n",
      "Iteration 287, loss = 0.18844099\n",
      "Iteration 288, loss = 0.18937460\n",
      "Iteration 289, loss = 0.18956667\n",
      "Iteration 290, loss = 0.18794228\n",
      "Iteration 291, loss = 0.18832601\n",
      "Iteration 292, loss = 0.18839621\n",
      "Iteration 293, loss = 0.18849553\n",
      "Iteration 294, loss = 0.18871493\n",
      "Iteration 295, loss = 0.18834838\n",
      "Iteration 296, loss = 0.18779777\n",
      "Iteration 297, loss = 0.18785746\n",
      "Iteration 298, loss = 0.18787292\n",
      "Iteration 299, loss = 0.18666146\n",
      "Iteration 300, loss = 0.18620593\n",
      "Iteration 301, loss = 0.18738236\n",
      "Iteration 302, loss = 0.18680835\n",
      "Iteration 303, loss = 0.18746006\n",
      "Iteration 304, loss = 0.18718547\n",
      "Iteration 305, loss = 0.18621536\n",
      "Iteration 306, loss = 0.18587694\n",
      "Iteration 307, loss = 0.18491101\n",
      "Iteration 308, loss = 0.18555069\n",
      "Iteration 309, loss = 0.18842872\n",
      "Iteration 310, loss = 0.18568373\n",
      "Iteration 311, loss = 0.18621439\n",
      "Iteration 312, loss = 0.18729807\n",
      "Iteration 313, loss = 0.18686331\n",
      "Iteration 314, loss = 0.18487241\n",
      "Iteration 315, loss = 0.18488259\n",
      "Iteration 316, loss = 0.18550004\n",
      "Iteration 317, loss = 0.18542489\n",
      "Iteration 318, loss = 0.18473603\n",
      "Iteration 319, loss = 0.18694899\n",
      "Iteration 320, loss = 0.18413192\n",
      "Iteration 321, loss = 0.18510382\n",
      "Iteration 322, loss = 0.18469183\n",
      "Iteration 323, loss = 0.18527868\n",
      "Iteration 324, loss = 0.18408762\n",
      "Iteration 325, loss = 0.18487711\n",
      "Iteration 326, loss = 0.18290024\n",
      "Iteration 327, loss = 0.18417484\n",
      "Iteration 328, loss = 0.18571587\n",
      "Iteration 329, loss = 0.18248676\n",
      "Iteration 330, loss = 0.18309461\n",
      "Iteration 331, loss = 0.18442612\n",
      "Iteration 332, loss = 0.18194829\n",
      "Iteration 333, loss = 0.18207504\n",
      "Iteration 334, loss = 0.18418716\n",
      "Iteration 335, loss = 0.18313966\n",
      "Iteration 336, loss = 0.18291314\n",
      "Iteration 337, loss = 0.18132750\n",
      "Iteration 338, loss = 0.18380692\n",
      "Iteration 339, loss = 0.18142788\n",
      "Iteration 340, loss = 0.18185587\n",
      "Iteration 341, loss = 0.18196041\n",
      "Iteration 342, loss = 0.18272464\n",
      "Iteration 343, loss = 0.18185638\n",
      "Iteration 344, loss = 0.18115958\n",
      "Iteration 345, loss = 0.18092379\n",
      "Iteration 346, loss = 0.18385803\n",
      "Iteration 347, loss = 0.18100992\n",
      "Iteration 348, loss = 0.18151347\n",
      "Iteration 349, loss = 0.18254796\n",
      "Iteration 350, loss = 0.18009336\n",
      "Iteration 351, loss = 0.18076770\n",
      "Iteration 352, loss = 0.18073910\n",
      "Iteration 353, loss = 0.18343345\n",
      "Iteration 354, loss = 0.18139972\n",
      "Iteration 355, loss = 0.17956118\n",
      "Iteration 356, loss = 0.18135562\n",
      "Iteration 357, loss = 0.17998810\n",
      "Iteration 358, loss = 0.17975694\n",
      "Iteration 359, loss = 0.18203147\n",
      "Iteration 360, loss = 0.18171309\n",
      "Iteration 361, loss = 0.18117772\n",
      "Iteration 362, loss = 0.18215092\n",
      "Iteration 363, loss = 0.17852388\n",
      "Iteration 364, loss = 0.18067051\n",
      "Iteration 365, loss = 0.17949435\n",
      "Iteration 366, loss = 0.17947502\n",
      "Iteration 367, loss = 0.17986296\n",
      "Iteration 368, loss = 0.17865861\n",
      "Iteration 369, loss = 0.18020489\n",
      "Iteration 370, loss = 0.17957400\n",
      "Iteration 371, loss = 0.18047716\n",
      "Iteration 372, loss = 0.17755884\n",
      "Iteration 373, loss = 0.17847482\n",
      "Iteration 374, loss = 0.17967365\n",
      "Iteration 375, loss = 0.17753763\n",
      "Iteration 376, loss = 0.17934831\n",
      "Iteration 377, loss = 0.17958473\n",
      "Iteration 378, loss = 0.18113623\n",
      "Iteration 379, loss = 0.17986768\n",
      "Iteration 380, loss = 0.17778122\n",
      "Iteration 381, loss = 0.17945962\n",
      "Iteration 382, loss = 0.17796775\n",
      "Iteration 383, loss = 0.17716428\n",
      "Iteration 384, loss = 0.17777999\n",
      "Iteration 385, loss = 0.17898274\n",
      "Iteration 386, loss = 0.17848808\n",
      "Iteration 387, loss = 0.17714571\n",
      "Iteration 388, loss = 0.17782906\n",
      "Iteration 389, loss = 0.17667349\n",
      "Iteration 390, loss = 0.17767424\n",
      "Iteration 391, loss = 0.17914609\n",
      "Iteration 392, loss = 0.17718434\n",
      "Iteration 393, loss = 0.17723598\n",
      "Iteration 394, loss = 0.17537440\n",
      "Iteration 395, loss = 0.17609505\n",
      "Iteration 396, loss = 0.17878787\n",
      "Iteration 397, loss = 0.17678064\n",
      "Iteration 398, loss = 0.17708770\n",
      "Iteration 399, loss = 0.17739952\n",
      "Iteration 400, loss = 0.17665991\n",
      "Iteration 401, loss = 0.17621724\n",
      "Iteration 402, loss = 0.17796639\n",
      "Iteration 403, loss = 0.17633068\n",
      "Iteration 404, loss = 0.17533679\n",
      "Iteration 405, loss = 0.17667662\n",
      "Iteration 406, loss = 0.17770392\n",
      "Iteration 407, loss = 0.17787246\n",
      "Iteration 408, loss = 0.17616453\n",
      "Iteration 409, loss = 0.17899653\n",
      "Iteration 410, loss = 0.17668103\n",
      "Iteration 411, loss = 0.17880413\n",
      "Iteration 412, loss = 0.17773036\n",
      "Iteration 413, loss = 0.17400702\n",
      "Iteration 414, loss = 0.17457432\n",
      "Iteration 415, loss = 0.17510968\n",
      "Iteration 416, loss = 0.17567021\n",
      "Iteration 417, loss = 0.17469777\n",
      "Iteration 418, loss = 0.17634447\n",
      "Iteration 419, loss = 0.17485710\n",
      "Iteration 420, loss = 0.17385866\n",
      "Iteration 421, loss = 0.17521296\n",
      "Iteration 422, loss = 0.17332498\n",
      "Iteration 423, loss = 0.17684263\n",
      "Iteration 424, loss = 0.17482699\n",
      "Iteration 425, loss = 0.17315387\n",
      "Iteration 426, loss = 0.17313118\n",
      "Iteration 427, loss = 0.17309907\n",
      "Iteration 428, loss = 0.17403092\n",
      "Iteration 429, loss = 0.17503255\n",
      "Iteration 430, loss = 0.17361123\n",
      "Iteration 431, loss = 0.17480339\n",
      "Iteration 432, loss = 0.17475911\n",
      "Iteration 433, loss = 0.17385797\n",
      "Iteration 434, loss = 0.17414974\n",
      "Iteration 435, loss = 0.17603205\n",
      "Iteration 436, loss = 0.17468217\n",
      "Iteration 437, loss = 0.17360365\n",
      "Iteration 438, loss = 0.17324893\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=1e-05,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_sk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rn_sk = rn_sk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rn_sk), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      6159\n",
      "           1       0.64      0.61      0.63      1982\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      8141\n",
      "   macro avg       0.76      0.75      0.76      8141\n",
      "weighted avg       0.82      0.82      0.82      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rn_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5482,  677],\n",
       "       [ 766, 1216]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rn_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo Redes Neurais com sklearn\n",
    "Desta maneira podemos observar que não fazer o escalonamento e o onehotencoder nas Redes Neurais pode ter uma diferença grande, com os testes cheguei a estes resultados:\n",
    "\n",
    "    83.5% Neural Networks(labelencoder + onehotencoder + escalonamento)\n",
    "    24.4% Neural Networks (labelencoder) - Muito lento\n",
    "    78.8% Neural Networks (labelencoder + onehotencoder) - Muito lento\n",
    "    84.8% Neural Networks (labelencoder + escalonamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais com a biblioteca ``Keras``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_kr = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camada inicial\n",
    "rn_kr.add(Dense(units = 55, activation = 'relu', input_dim = 108))\n",
    "# Camada oculta\n",
    "rn_kr.add(Dense(units = 55, activation = 'relu'))\n",
    "# Camada de saida\n",
    "rn_kr.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "# Compilação\n",
    "rn_kr.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000000F580C8B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000000F580C8B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.3460 - accuracy: 0.8405\n",
      "Epoch 2/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.3151 - accuracy: 0.8531\n",
      "Epoch 3/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.3062 - accuracy: 0.8586\n",
      "Epoch 4/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2998 - accuracy: 0.8615\n",
      "Epoch 5/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2955 - accuracy: 0.8635\n",
      "Epoch 6/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2913 - accuracy: 0.8656\n",
      "Epoch 7/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2864 - accuracy: 0.8663\n",
      "Epoch 8/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2822 - accuracy: 0.8698\n",
      "Epoch 9/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2775 - accuracy: 0.8704\n",
      "Epoch 10/100\n",
      "2442/2442 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.87 - 3s 1ms/step - loss: 0.2738 - accuracy: 0.8729\n",
      "Epoch 11/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2703 - accuracy: 0.8735\n",
      "Epoch 12/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2655 - accuracy: 0.8778\n",
      "Epoch 13/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2622 - accuracy: 0.8773\n",
      "Epoch 14/100\n",
      "2442/2442 [==============================] - 4s 1ms/step - loss: 0.2577 - accuracy: 0.8795\n",
      "Epoch 15/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2537 - accuracy: 0.8832\n",
      "Epoch 16/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2504 - accuracy: 0.8836\n",
      "Epoch 17/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2458 - accuracy: 0.8853\n",
      "Epoch 18/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2432 - accuracy: 0.8878\n",
      "Epoch 19/100\n",
      "2442/2442 [==============================] - 6s 2ms/step - loss: 0.2409 - accuracy: 0.8894\n",
      "Epoch 20/100\n",
      "2442/2442 [==============================] - 6s 2ms/step - loss: 0.2365 - accuracy: 0.8909\n",
      "Epoch 21/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2338 - accuracy: 0.8922\n",
      "Epoch 22/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2298 - accuracy: 0.8933\n",
      "Epoch 23/100\n",
      "2442/2442 [==============================] - 6s 2ms/step - loss: 0.2278 - accuracy: 0.8951\n",
      "Epoch 24/100\n",
      "2442/2442 [==============================] - 6s 3ms/step - loss: 0.2255 - accuracy: 0.8953\n",
      "Epoch 25/100\n",
      "2442/2442 [==============================] - 6s 3ms/step - loss: 0.2226 - accuracy: 0.8961\n",
      "Epoch 26/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2195 - accuracy: 0.8981\n",
      "Epoch 27/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2185 - accuracy: 0.8981\n",
      "Epoch 28/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2163 - accuracy: 0.8993\n",
      "Epoch 29/100\n",
      "2442/2442 [==============================] - 6s 2ms/step - loss: 0.2139 - accuracy: 0.9011\n",
      "Epoch 30/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2112 - accuracy: 0.9028\n",
      "Epoch 31/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2096 - accuracy: 0.9028\n",
      "Epoch 32/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2071 - accuracy: 0.9029\n",
      "Epoch 33/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2048 - accuracy: 0.9048\n",
      "Epoch 34/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.2046 - accuracy: 0.9045\n",
      "Epoch 35/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.2017 - accuracy: 0.9048\n",
      "Epoch 36/100\n",
      "2442/2442 [==============================] - 6s 2ms/step - loss: 0.2012 - accuracy: 0.9075\n",
      "Epoch 37/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1984 - accuracy: 0.9071\n",
      "Epoch 38/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1969 - accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1953 - accuracy: 0.9088\n",
      "Epoch 40/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1941 - accuracy: 0.9094\n",
      "Epoch 41/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1931 - accuracy: 0.9095\n",
      "Epoch 42/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1915 - accuracy: 0.9107\n",
      "Epoch 43/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1896 - accuracy: 0.9120\n",
      "Epoch 44/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1877 - accuracy: 0.9135\n",
      "Epoch 45/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1864 - accuracy: 0.9122\n",
      "Epoch 46/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1857 - accuracy: 0.9116\n",
      "Epoch 47/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1837 - accuracy: 0.9131\n",
      "Epoch 48/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1826 - accuracy: 0.9145\n",
      "Epoch 49/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1819 - accuracy: 0.9143\n",
      "Epoch 50/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1817 - accuracy: 0.9148\n",
      "Epoch 51/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1796 - accuracy: 0.9154\n",
      "Epoch 52/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1789 - accuracy: 0.9174\n",
      "Epoch 53/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1797 - accuracy: 0.9139\n",
      "Epoch 54/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1765 - accuracy: 0.9170\n",
      "Epoch 55/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1772 - accuracy: 0.9168\n",
      "Epoch 56/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1732 - accuracy: 0.9176\n",
      "Epoch 57/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1752 - accuracy: 0.9174\n",
      "Epoch 58/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1735 - accuracy: 0.9183\n",
      "Epoch 59/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1749 - accuracy: 0.9176\n",
      "Epoch 60/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1704 - accuracy: 0.9210\n",
      "Epoch 61/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1704 - accuracy: 0.9217\n",
      "Epoch 62/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1699 - accuracy: 0.9198\n",
      "Epoch 63/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1692 - accuracy: 0.9212\n",
      "Epoch 64/100\n",
      "2442/2442 [==============================] - 4s 1ms/step - loss: 0.1681 - accuracy: 0.9220\n",
      "Epoch 65/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1673 - accuracy: 0.9208\n",
      "Epoch 66/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1662 - accuracy: 0.9222\n",
      "Epoch 67/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1679 - accuracy: 0.9209\n",
      "Epoch 68/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1649 - accuracy: 0.9229\n",
      "Epoch 69/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1664 - accuracy: 0.9220\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1635 - accuracy: 0.9240\n",
      "Epoch 71/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1620 - accuracy: 0.9235\n",
      "Epoch 72/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1635 - accuracy: 0.9235\n",
      "Epoch 73/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1637 - accuracy: 0.9235\n",
      "Epoch 74/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1631 - accuracy: 0.9249\n",
      "Epoch 75/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1629 - accuracy: 0.9245\n",
      "Epoch 76/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1603 - accuracy: 0.9244\n",
      "Epoch 77/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1610 - accuracy: 0.9248\n",
      "Epoch 78/100\n",
      "2442/2442 [==============================] - 4s 1ms/step - loss: 0.1593 - accuracy: 0.9263\n",
      "Epoch 79/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1596 - accuracy: 0.9245\n",
      "Epoch 80/100\n",
      "2442/2442 [==============================] - 4s 1ms/step - loss: 0.1592 - accuracy: 0.9252\n",
      "Epoch 81/100\n",
      "2442/2442 [==============================] - 4s 1ms/step - loss: 0.1573 - accuracy: 0.9267\n",
      "Epoch 82/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1572 - accuracy: 0.9271\n",
      "Epoch 83/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1586 - accuracy: 0.9254\n",
      "Epoch 84/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1563 - accuracy: 0.9265\n",
      "Epoch 85/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1570 - accuracy: 0.9273\n",
      "Epoch 86/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1543 - accuracy: 0.9304\n",
      "Epoch 87/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1538 - accuracy: 0.9286\n",
      "Epoch 88/100\n",
      "2442/2442 [==============================] - 4s 1ms/step - loss: 0.1546 - accuracy: 0.9281\n",
      "Epoch 89/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1558 - accuracy: 0.9282\n",
      "Epoch 90/100\n",
      "2442/2442 [==============================] - 3s 1ms/step - loss: 0.1534 - accuracy: 0.9294\n",
      "Epoch 91/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1518 - accuracy: 0.9290\n",
      "Epoch 92/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1528 - accuracy: 0.9294\n",
      "Epoch 93/100\n",
      "2442/2442 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - 5s 2ms/step - loss: 0.1503 - accuracy: 0.9309\n",
      "Epoch 94/100\n",
      "2442/2442 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.92 - 5s 2ms/step - loss: 0.1515 - accuracy: 0.9287\n",
      "Epoch 95/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1488 - accuracy: 0.9307\n",
      "Epoch 96/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1505 - accuracy: 0.9292\n",
      "Epoch 97/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1505 - accuracy: 0.9309\n",
      "Epoch 98/100\n",
      "2442/2442 [==============================] - 5s 2ms/step - loss: 0.1485 - accuracy: 0.9314\n",
      "Epoch 99/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1493 - accuracy: 0.9320\n",
      "Epoch 100/100\n",
      "2442/2442 [==============================] - 4s 2ms/step - loss: 0.1481 - accuracy: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xf60ee7fc8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_kr.fit(X_train, y_train, batch_size=10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000000F6685A678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000000F6685A678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "y_pred_rn_kr = rn_kr.predict(X_test)\n",
    "y_pred_rn_kr = (y_pred_rn_kr > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rn_kr), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      6159\n",
      "           1       0.64      0.63      0.63      1982\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      8141\n",
      "   macro avg       0.76      0.76      0.76      8141\n",
      "weighted avg       0.82      0.82      0.82      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rn_kr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5458,  701],\n",
       "       [ 740, 1242]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rn_kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Finais do algoritmo Redes Neurais com Keras\n",
    "Tive que fazer vários testes cada um com a transformação diferente, e cheguei a estes resultados:\n",
    "\n",
    "    81.7% Neural Networks(labelencoder + onehotencoder + escalonamento)\n",
    "    75.5%Neural Networks (labelencoder) - Muito lento\n",
    "    24.4% Neural Networks (labelencoder + onehotencoder) - Muito lento\n",
    "    85.1% Neural Networks (labelencoder + escalonamento)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
