{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados credit-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('credit-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clientid        income        age         loan  default\n",
       "0         1  66155.925095  59.017015  8106.532131        0\n",
       "1         2  34415.153966  48.117153  6564.745018        0\n",
       "2         3  57317.170063  63.108049  8020.953296        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 5 colunas presentes no dataset fornecido, sendo três delas variáveis características (dados de entrada) e um delas uma variável-alvo (que queremos que o nosso modelo seja capaz de prever).\n",
    "\n",
    "As variáveis características são:\n",
    "\n",
    "    income       - O total de renda\n",
    "    age          - Idade do usuário\n",
    "    loan         - O empréstimo que o usuário fez\n",
    "\n",
    "A variável-alvo é:\n",
    "\n",
    "    Default    - um tipo *binário* que indica se o usuário pagou ou não: \n",
    "            0      - Usuário não pagou o empréstimo\n",
    "            1      - Usuário pagou o empréstimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 5 columns):\n",
      "clientid    2000 non-null int64\n",
      "income      2000 non-null float64\n",
      "age         1997 non-null float64\n",
      "loan        2000 non-null float64\n",
      "default     2000 non-null int64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É notado que existem variáveis do tipo ``float64`` (números \"decimais\").\n",
    "\n",
    "Já que todos os valores do nosso dataset são numéricos, nós não precisaremos fazer o a transformação do tipo \"object\" para o tipo númerico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ``describe()`` gera várias informações sobre as variáveis numéricas que também podem ser úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45331.600018</td>\n",
       "      <td>40.807559</td>\n",
       "      <td>4444.369695</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>577.494589</td>\n",
       "      <td>14326.327119</td>\n",
       "      <td>13.624469</td>\n",
       "      <td>3045.410024</td>\n",
       "      <td>0.348624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20014.489470</td>\n",
       "      <td>-52.423280</td>\n",
       "      <td>1.377630</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>500.750000</td>\n",
       "      <td>32796.459717</td>\n",
       "      <td>28.990415</td>\n",
       "      <td>1939.708847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45789.117313</td>\n",
       "      <td>41.317159</td>\n",
       "      <td>3974.719419</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1500.250000</td>\n",
       "      <td>57791.281668</td>\n",
       "      <td>52.587040</td>\n",
       "      <td>6432.410625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>69995.685578</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>13766.051239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          clientid        income          age          loan      default\n",
       "count  2000.000000   2000.000000  1997.000000   2000.000000  2000.000000\n",
       "mean   1000.500000  45331.600018    40.807559   4444.369695     0.141500\n",
       "std     577.494589  14326.327119    13.624469   3045.410024     0.348624\n",
       "min       1.000000  20014.489470   -52.423280      1.377630     0.000000\n",
       "25%     500.750000  32796.459717    28.990415   1939.708847     0.000000\n",
       "50%    1000.500000  45789.117313    41.317159   3974.719419     0.000000\n",
       "75%    1500.250000  57791.281668    52.587040   6432.410625     0.000000\n",
       "max    2000.000000  69995.685578    63.971796  13766.051239     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 1: tratando dados negativos\n",
    "Para tratar os dados negativos em nosso conjunto de dados, nós iremos alterar os valores negativos pela média de toda coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.80755937840458"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tirar a média de todos os valores da idade, e substituir os valores faltantes pela média.\n",
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.92770044906149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# porém devemos pegar a média dos valores positivos.\n",
    "df['age'][df.age > 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui alteramos as idades negativas para o valor da média acima.\n",
    "df.loc[df.age < 0, 'age'] = 40.92\n",
    "# ou\n",
    "df[df['age'] < 0] = 40.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clientid, income, age, loan, default]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nenhum valor :D\n",
    "df.loc[df['age'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15    40.92\n",
       "21    40.92\n",
       "26    40.92\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ou podemos buscar pelos ID's (já que a base de dados é pequena)\n",
    "df.loc[[15, 21, 26], \"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição das features do nosso modelo\n",
    "Para isso, criaremos a váriavel X que receberá os previsores do nosso modelo, e a variavel y que receberá a classe do nosso modelo.\n",
    "\n",
    "Também retiraremos a coluna 'clientid' que não terá relevância no nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das colunas que serão features (nota-se que a coluna 'clientid' não está presente)\n",
    "features = ['income', 'age', 'loan']\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"default\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df[features].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encontrando dados faltantes (NaN)\n",
    "Nesta parte será feito a procura dos dados faltantes no nosso dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1997\n",
       "True        3\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Com este comando descobrimos que há valores faltantes\n",
    "pd.isnull(df['age']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clientid    0\n",
       "income      0\n",
       "age         3\n",
       "loan        0\n",
       "default     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ou os dados faltantes de todas colunas\n",
    "faltantes = df.isnull().sum()\n",
    "faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clientid    0.00\n",
       "income      0.00\n",
       "age         0.15\n",
       "loan        0.00\n",
       "default     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dados faltantes em %\n",
    "faltantes_percentual = (df.isnull().sum() / len(df['clientid'])) * 100\n",
    "faltantes_percentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59417.805406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2082.625938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>48528.852796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6155.784670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23526.302555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2862.010139</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientid        income  age         loan  default\n",
       "28      29.0  59417.805406  NaN  2082.625938      0.0\n",
       "30      31.0  48528.852796  NaN  6155.784670      0.0\n",
       "31      32.0  23526.302555  NaN  2862.010139      0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# com este comando podemos achar quem está com 'NaN'\n",
    "df.loc[pd.isnull(df['age'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 2: Tratando dados faltantes (NaN)\n",
    "\n",
    "Para tratar os dados faltantes em nosso conjunto de dados, iremos agora utilizar uma transformação pronta da biblioteca scikit-learn, chamada **SimpleImputer**.\n",
    "\n",
    "Neste exemplo iremos simplesmente transformar todos os valores faltantes pela média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aqui é feita a estratégia do imputer, que no caso vamos mudar os valores NaN pela média da coluna\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aqui nós fazemos a mudança dos NaN apenas para a variavel 'imputer'\n",
    "imputer = imputer.fit(X[:, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora o 'previsores' recebe a transformação dos dados do 'imputer'\n",
    "X[:, 0:3] = imputer.transform(X[:, 0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Outra solução\n",
    "Nós também podemos fazer o tratamento NaN 'a mão', sem importações, porém lembrando que altera o dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59417.805406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2082.625938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>48528.852796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6155.784670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23526.302555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2862.010139</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientid        income  age         loan  default\n",
       "28      29.0  59417.805406  NaN  2082.625938      0.0\n",
       "30      31.0  48528.852796  NaN  6155.784670      0.0\n",
       "31      32.0  23526.302555  NaN  2862.010139      0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# antes da transformação\n",
    "df[df['age'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clientid, income, age, loan, default]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# após a transformação\n",
    "df[df['age'].isnull() == True].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 3: Escalonamento dos atributos (Padronização dos dados)\n",
    "Nossos dados estão todos fora da mesma escala, e para isso nós temos que fazer a padronização deles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.61559251e+04, 5.90170151e+01, 8.10653213e+03],\n",
       "       [3.44151540e+04, 4.81171531e+01, 6.56474502e+03],\n",
       "       [5.73171701e+04, 6.31080495e+01, 8.02095330e+03],\n",
       "       ...,\n",
       "       [4.43114493e+04, 2.80171669e+01, 5.52278669e+03],\n",
       "       [4.37560566e+04, 6.39717958e+01, 1.62272260e+03],\n",
       "       [6.94365796e+04, 5.61526170e+01, 7.37883360e+03]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45393393,  1.36538093,  1.20281942],\n",
       "       [-0.76217555,  0.5426602 ,  0.69642695],\n",
       "       [ 0.83682073,  1.67417189,  1.17471147],\n",
       "       ...,\n",
       "       [-0.07122592, -0.97448519,  0.35420081],\n",
       "       [-0.11000289,  1.73936739, -0.92675625],\n",
       "       [ 1.682986  ,  1.14917639,  0.96381038]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando os modelos de classificação\n",
    "Finalizado o pré-processamento, já temos o conjunto de dados no formato necessário para o treinamento do nosso modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações dos algoritmos de ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Redes neurais com keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando o dataset em um conjunto de treino e um conjunto de teste\n",
    "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes \n",
    "O algoritmo Naive Bayes é um algoritmo simples de classificação, que utiliza dados históricos para prever a classificação de um novo dado. Ele funciona calculando a probabilidade de um evento ocorrer dado que outro evento já ocorreu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Parte do treinamento\n",
    "nb.fit(X_train, y_train)\n",
    "# Parte do teste, predict serve para testar\n",
    "y_pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 94.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Naive Bayes\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_nb), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       436\n",
      "         1.0       0.84      0.64      0.73        64\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       500\n",
      "   macro avg       0.89      0.81      0.85       500\n",
      "weighted avg       0.93      0.94      0.93       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[428,   8],\n",
       "       [ 23,  41]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "O algoritmo Decision Tree são modelos estatísticos que utilizam um treinamento supervisionado para a classificação e previsão de dados, Estes modelos utilizam a estratégia de dividir para conquistar: um problema complexo é decomposto em sub-problemas mais simples e recursivamente esta técnica é aplicada a cada sub-problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 98.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Decision Tree\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_dt), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99       436\n",
      "         1.0       0.91      0.97      0.94        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       500\n",
      "   macro avg       0.95      0.98      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[430,   6],\n",
       "       [  2,  62]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "O algoritmo Random Forest cria uma floresta de um modo aleatório, criando várias árvores de decisão e as combinando,cada árvore tenta estimar uma classificação e isso é chamado como “voto”, assim, para obter uma predição com maior acurácia e mais estável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 98.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo Random Forest\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rf), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99       436\n",
      "         1.0       0.95      0.89      0.92        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       500\n",
      "   macro avg       0.97      0.94      0.95       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[433,   3],\n",
       "       [  7,  57]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN (Vizinhos mais próximos)\n",
    "O algoritmo KNN ou k-vizinhos mais próximos é um algoritmo bem simples de machine learning. Ele usa algum tipo de medida de similaridade para dizer em qual classe o novo dado se classifica, neste caso utilizaremos 5 vizinhos mais próximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski', p = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 99.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo kNN\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_kn), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       436\n",
      "         1.0       0.94      0.95      0.95        64\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.99      0.99      0.99       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_kn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[432,   4],\n",
       "       [  3,  61]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_kn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logistica\n",
    "O algoritmo de regressão logística é usada onde uma saída discreta é esperada, (ex. Prever se um usuário é um bom ou mal pagador).Normalmente, a regressão logística usa alguma função para espremer valores para um determinado intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rl = rl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 94.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo kNN\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rl), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       436\n",
      "         1.0       0.78      0.78      0.78        64\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       500\n",
      "   macro avg       0.87      0.87      0.87       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[422,  14],\n",
       "       [ 14,  50]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Máquinas de vetores de suporte)\n",
    "O algoritmo de SVM separa os pontos de dados usando uma linha. Esta linha é escolhida de tal forma que será mais importante dos pontos de dados mais próximos em 2 categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'rbf', C = 2.0, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 99.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo kNN\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_svm), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99       436\n",
      "         1.0       0.97      0.94      0.95        64\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       500\n",
      "   macro avg       0.98      0.97      0.97       500\n",
      "weighted avg       0.99      0.99      0.99       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[434,   2],\n",
       "       [  4,  60]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neurais\n",
    "O objetivo do algoritmo de Redes neurais é imitar o sistema nervoso de humanos no processo de aprendizagem, ela é inspirada nas redes neurais biológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais com a biblioteca ``sklearn``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = MLPClassifier(verbose=True, max_iter=100, tol = 0.000010, solver = 'adam', hidden_layer_sizes= (100), activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.82643083\n",
      "Iteration 2, loss = 0.74027504\n",
      "Iteration 3, loss = 0.66385755\n",
      "Iteration 4, loss = 0.59789300\n",
      "Iteration 5, loss = 0.54147403\n",
      "Iteration 6, loss = 0.49250850\n",
      "Iteration 7, loss = 0.45048935\n",
      "Iteration 8, loss = 0.41415965\n",
      "Iteration 9, loss = 0.38260762\n",
      "Iteration 10, loss = 0.35499412\n",
      "Iteration 11, loss = 0.33118433\n",
      "Iteration 12, loss = 0.30994897\n",
      "Iteration 13, loss = 0.29135575\n",
      "Iteration 14, loss = 0.27483603\n",
      "Iteration 15, loss = 0.26005814\n",
      "Iteration 16, loss = 0.24673154\n",
      "Iteration 17, loss = 0.23477151\n",
      "Iteration 18, loss = 0.22394420\n",
      "Iteration 19, loss = 0.21407142\n",
      "Iteration 20, loss = 0.20516912\n",
      "Iteration 21, loss = 0.19704154\n",
      "Iteration 22, loss = 0.18947024\n",
      "Iteration 23, loss = 0.18265776\n",
      "Iteration 24, loss = 0.17627689\n",
      "Iteration 25, loss = 0.17037564\n",
      "Iteration 26, loss = 0.16492699\n",
      "Iteration 27, loss = 0.15990927\n",
      "Iteration 28, loss = 0.15515962\n",
      "Iteration 29, loss = 0.15076590\n",
      "Iteration 30, loss = 0.14670879\n",
      "Iteration 31, loss = 0.14284676\n",
      "Iteration 32, loss = 0.13927025\n",
      "Iteration 33, loss = 0.13590954\n",
      "Iteration 34, loss = 0.13271314\n",
      "Iteration 35, loss = 0.12973145\n",
      "Iteration 36, loss = 0.12685067\n",
      "Iteration 37, loss = 0.12425576\n",
      "Iteration 38, loss = 0.12162656\n",
      "Iteration 39, loss = 0.11922530\n",
      "Iteration 40, loss = 0.11700483\n",
      "Iteration 41, loss = 0.11480036\n",
      "Iteration 42, loss = 0.11283705\n",
      "Iteration 43, loss = 0.11092408\n",
      "Iteration 44, loss = 0.10907280\n",
      "Iteration 45, loss = 0.10731758\n",
      "Iteration 46, loss = 0.10557751\n",
      "Iteration 47, loss = 0.10401406\n",
      "Iteration 48, loss = 0.10249511\n",
      "Iteration 49, loss = 0.10099466\n",
      "Iteration 50, loss = 0.09961949\n",
      "Iteration 51, loss = 0.09826793\n",
      "Iteration 52, loss = 0.09686450\n",
      "Iteration 53, loss = 0.09557849\n",
      "Iteration 54, loss = 0.09441272\n",
      "Iteration 55, loss = 0.09317469\n",
      "Iteration 56, loss = 0.09199875\n",
      "Iteration 57, loss = 0.09091017\n",
      "Iteration 58, loss = 0.08975482\n",
      "Iteration 59, loss = 0.08876257\n",
      "Iteration 60, loss = 0.08769194\n",
      "Iteration 61, loss = 0.08667743\n",
      "Iteration 62, loss = 0.08571348\n",
      "Iteration 63, loss = 0.08474195\n",
      "Iteration 64, loss = 0.08379441\n",
      "Iteration 65, loss = 0.08288576\n",
      "Iteration 66, loss = 0.08202774\n",
      "Iteration 67, loss = 0.08107818\n",
      "Iteration 68, loss = 0.08030285\n",
      "Iteration 69, loss = 0.07938063\n",
      "Iteration 70, loss = 0.07868736\n",
      "Iteration 71, loss = 0.07774841\n",
      "Iteration 72, loss = 0.07700928\n",
      "Iteration 73, loss = 0.07632149\n",
      "Iteration 74, loss = 0.07545508\n",
      "Iteration 75, loss = 0.07471699\n",
      "Iteration 76, loss = 0.07412172\n",
      "Iteration 77, loss = 0.07324444\n",
      "Iteration 78, loss = 0.07252983\n",
      "Iteration 79, loss = 0.07188653\n",
      "Iteration 80, loss = 0.07119311\n",
      "Iteration 81, loss = 0.07042067\n",
      "Iteration 82, loss = 0.06986631\n",
      "Iteration 83, loss = 0.06920770\n",
      "Iteration 84, loss = 0.06854424\n",
      "Iteration 85, loss = 0.06789086\n",
      "Iteration 86, loss = 0.06727673\n",
      "Iteration 87, loss = 0.06669012\n",
      "Iteration 88, loss = 0.06611750\n",
      "Iteration 89, loss = 0.06557801\n",
      "Iteration 90, loss = 0.06491161\n",
      "Iteration 91, loss = 0.06438217\n",
      "Iteration 92, loss = 0.06396870\n",
      "Iteration 93, loss = 0.06337430\n",
      "Iteration 94, loss = 0.06276378\n",
      "Iteration 95, loss = 0.06227542\n",
      "Iteration 96, loss = 0.06170150\n",
      "Iteration 97, loss = 0.06125600\n",
      "Iteration 98, loss = 0.06068228\n",
      "Iteration 99, loss = 0.06023852\n",
      "Iteration 100, loss = 0.05981839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=100, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=1e-05,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rn = rn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 98.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo kNN\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rn), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99       436\n",
      "         1.0       0.93      0.88      0.90        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       500\n",
      "   macro avg       0.96      0.93      0.94       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[432,   4],\n",
       "       [  8,  56]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão de acertos\n",
    "confusion_matrix(y_test, y_pred_rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais com a biblioteca ``Keras``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_keras = Sequential()\n",
    "# neurônios, ativação, neurônios iniciais \n",
    "rn_keras.add(Dense(units = 2, activation = 'relu', input_dim = 3))\n",
    "# Camada 2 (oculta)\n",
    "rn_keras.add(Dense(units = 2, activation = 'relu'))\n",
    "# Camada de saida\n",
    "rn_keras.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "# Ajustes finais (Adam, calculo do erro (binário), métricas seria a %)\n",
    "rn_keras.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000072CCBEBF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000072CCBEBF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.8540\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6211 - accuracy: 0.8540\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.8540\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8540\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 914us/step - loss: 0.3914 - accuracy: 0.8540\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 994us/step - loss: 0.3512 - accuracy: 0.8540\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8540\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8540\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8540\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8540\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.8540\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.8540\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.8540\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 887us/step - loss: 0.1944 - accuracy: 0.8540\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.8540\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8540\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9047\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9387\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9447\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9453\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9467\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9473\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9487\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9467\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9480\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 888us/step - loss: 0.1450 - accuracy: 0.9467\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9473\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9467\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 881us/step - loss: 0.1403 - accuracy: 0.9467\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.94 - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9487\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 941us/step - loss: 0.1378 - accuracy: 0.9487\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9453\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 934us/step - loss: 0.1354 - accuracy: 0.9453\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 981us/step - loss: 0.1347 - accuracy: 0.9473\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9467\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9460\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9447\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9460\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9480\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9460\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9460\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9487\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9453\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 941us/step - loss: 0.1287 - accuracy: 0.9473\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9473\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9480\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 781us/step - loss: 0.1271 - accuracy: 0.9467\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9480\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9473\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x72ccc1bb48>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size (a cada 10 registros é atualizado os pesos)\n",
    "# nb_epochs (epócas: executar 100 vezes)\n",
    "rn_keras.fit(X_train, y_train, batch_size = 10, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000072CD292288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000072CD292288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "y_pred_rn_keras = rn_keras.predict(X_test)\n",
    "y_pred_rn_keras = (y_pred_rn_keras > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 95.0%\n"
     ]
    }
   ],
   "source": [
    "# Acurácia alcançada pelo algortimo kNN\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred_rn_keras), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       436\n",
      "         1.0       0.80      0.80      0.80        64\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       500\n",
      "   macro avg       0.88      0.88      0.88       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rn_keras))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
